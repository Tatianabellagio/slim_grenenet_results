{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82f1162e-bf4d-4153-8abb-c966e285ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## results model meixi \n",
    "## IMPORT ALLELES FREQ \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53dafcca-1b23-47cd-a938-f698d20d9bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_offset_nooffset_partitions = pd.read_csv('/home/tbellagio/scratch/slim_grenenet/data/dict_offset_nooffset_partitions.csv')\n",
    "\n",
    "pattern = os.path.join('/home/tbellagio/scratch/slim_grenenet/results', '**', 'lmm_nopc_results10env.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "627529c3-db52-4f61-951c-65c262a335e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lmm_pc_results_files = glob.glob(pattern, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d716c915-97aa-4657-81c1-8d63f5ec955f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lmm_pc_results_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1cd2c55-2cd8-4b92-b9f1-ceab2c6ffa77",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m results_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m lmm_pc_results_files:\n\u001b[0;32m----> 3\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     results_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mlen\u001b[39m(results))\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:873\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:848\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:2025\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "results_list = []\n",
    "for i in lmm_pc_results_files:\n",
    "    results = pd.read_csv(i)\n",
    "    results_list.append(len(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d035b92c-b2a1-474f-acbc-5b4f3a87d0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50698e8f-8b42-412a-ba73-1ac88a05964a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3235480, 3235480, 3235480, 3235480, 3235480, 3235480, 3235480, 3235480]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb1baf-6eaa-4ca4-9c77-5ea2b3386167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_rows(results_lmm):\n",
    "    max_value = results_lmm.index.str.split('.').str[1].astype(int).max()\n",
    "    expected_rows = [f'result.{i}' for i in range(1,max_value + 1)]\n",
    "    missing_rows = set(expected_rows) - set(results_lmm.index)\n",
    "    #check \n",
    "    #set(results_lmm.index) -  set(expected_rows)\n",
    "\n",
    "    # Initialize an empty list to store dictionaries\n",
    "    list_of_dicts = []\n",
    "\n",
    "    # Create dictionaries for each index value and add them to the list\n",
    "    for index in missing_rows:\n",
    "        new_row = {'index': index, 'R2m': np.nan, 'R2c': np.nan, 'beta': np.nan, 'beta_p': np.nan, 'BIC': np.nan}\n",
    "        list_of_dicts.append(new_row)\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    missing_rows = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "    results_lmm = results_lmm.reset_index()\n",
    "    results_lmm = pd.concat([results_lmm,missing_rows])\n",
    "    results_lmm['index'] = results_lmm['index'].str.split('.').str[1].astype(int)\n",
    "\n",
    "    results_lmm = results_lmm.sort_values(by = 'index')\n",
    "\n",
    "    results_lmm = results_lmm.reset_index(drop=True).drop('index',axis=1)\n",
    "    #len(results_lmm)\n",
    "\n",
    "    return results_lmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3897d5-208b-415a-b39f-7f9e2fa113be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_wtreshold(name, results_lmm, th, min_pvalue):\n",
    "\n",
    "    results_lmm['sig'] = results_lmm['p_value_env']<= th\n",
    "\n",
    "    true_positives = len(results_lmm[(results_lmm['is_within_range'] ==True) & (results_lmm['sig'] ==True)])\n",
    "\n",
    "    true_negatives = len(results_lmm[(results_lmm['is_within_range'] ==False) & (results_lmm['sig'] ==False)])\n",
    "\n",
    "    false_negatives = len(results_lmm[(results_lmm['is_within_range'] ==True) & (results_lmm['sig'] ==False)])\n",
    "\n",
    "    false_positives = len(results_lmm[(results_lmm['is_within_range'] ==False) & (results_lmm['sig'] ==True)])\n",
    "\n",
    "    if false_positives + true_positives == 0:\n",
    "        fdr = np.nan  # Set FDR to 0 if the denominator is zero\n",
    "    else:\n",
    "        fdr = false_positives / (false_positives + true_positives)\n",
    "\n",
    "    new_row = {'name': name,\n",
    "               'true_positives': true_positives,\n",
    "               'true_negatives': true_negatives,\n",
    "               'false_negatives': false_negatives,\n",
    "               'false_positives': false_positives,\n",
    "               'fdr': fdr,\n",
    "               'min_p_value': min_pvalue, \n",
    "               'th': str(th)}\n",
    "\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ab855-b935-44ad-8e9b-2ba7df764496",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_metrics = pd.DataFrame(columns=['name', 'true_positives', 'true_negatives', 'false_negatives', 'false_positives', 'fdr', 'min_p_value', 'th'])\n",
    "\n",
    "for result in lmm_pc_results_files: \n",
    "\n",
    "    name = result.split('/')[-3] + '_' + result.split('/')[-4] + '_' + result.split('/')[-5]\n",
    "\n",
    "    allele_freq_norm_file = result.replace('/lmm/lmm_nopc_results10env.csv','/allele_freq_norm10env.csv')\n",
    "    causal_loci_file = result.split('arq')[0] + 'arq' + result.split('arq')[1].split('/')[0] + '/loci_effectsize.csv'\n",
    "\n",
    "    results_lmm = pd.read_csv(result,index_col=[0])\n",
    "\n",
    "    bc = 0.05 / len(results_lmm)\n",
    "\n",
    "    ## first i need to check that all results are there \n",
    "    results_lmm = add_missing_rows(results_lmm)\n",
    "\n",
    "    ## read allele freq norm to get chrom pos \n",
    "    allele_freq_norm = pd.read_csv(allele_freq_norm_file)\n",
    "    results_lmm = pd.concat([allele_freq_norm['chrom_pos'], results_lmm],axis=1)\n",
    "\n",
    "    #get the causal loci \n",
    "    causal_loci = pd.read_csv(causal_loci_file)\n",
    "    causal_loci = causal_loci.merge(dict_offset_nooffset_partitions, left_on = 'pos', right_on = 'offset')\n",
    "    results_lmm = results_lmm.merge(dict_offset_nooffset_partitions[['offset', 'partition']], left_on = 'chrom_pos', right_on = 'offset')\n",
    "    results_lmm.loc[:, 'is_within_range'] = results_lmm['partition'].isin(causal_loci['partition'])\n",
    "\n",
    "\n",
    "    ## get the min p value for teh records \n",
    "    min_pvalue = results_lmm['p_value_env'].min()\n",
    "\n",
    "\n",
    "    for i in [0.05, 0.0005, 0.000005, 0.00000005, bc]:\n",
    "        new_row = metrics_wtreshold(name, results_lmm, i, min_pvalue)\n",
    "        result_metrics.loc[len(result_metrics)] = new_row\n",
    "result_metrics.to_csv('results_lmm_nopc_10env.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61b2cf4f-ea8c-436e-b237-a73c6e4fe03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>fdr</th>\n",
       "      <th>min_p_value</th>\n",
       "      <th>th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>5e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>5e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>0.016666666666666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>strongsel_mediumh_arq_mediumfreq_monogen_2</td>\n",
       "      <td>0</td>\n",
       "      <td>3235178</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>strongsel_mediumh_arq_mediumfreq_monogen_2</td>\n",
       "      <td>0</td>\n",
       "      <td>3235178</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>strongsel_mediumh_arq_mediumfreq_monogen_2</td>\n",
       "      <td>0</td>\n",
       "      <td>3235178</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>5e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>strongsel_mediumh_arq_mediumfreq_monogen_2</td>\n",
       "      <td>0</td>\n",
       "      <td>3235178</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>5e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>strongsel_mediumh_arq_mediumfreq_monogen_2</td>\n",
       "      <td>0</td>\n",
       "      <td>3235178</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>0.016666666666666666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name  true_positives  \\\n",
       "0    strongsel_mediumh_arq_highfreq_onehpoly_4               0   \n",
       "1    strongsel_mediumh_arq_highfreq_onehpoly_4               0   \n",
       "2    strongsel_mediumh_arq_highfreq_onehpoly_4               0   \n",
       "3    strongsel_mediumh_arq_highfreq_onehpoly_4               0   \n",
       "4    strongsel_mediumh_arq_highfreq_onehpoly_4               0   \n",
       "..                                         ...             ...   \n",
       "85  strongsel_mediumh_arq_mediumfreq_monogen_2               0   \n",
       "86  strongsel_mediumh_arq_mediumfreq_monogen_2               0   \n",
       "87  strongsel_mediumh_arq_mediumfreq_monogen_2               0   \n",
       "88  strongsel_mediumh_arq_mediumfreq_monogen_2               0   \n",
       "89  strongsel_mediumh_arq_mediumfreq_monogen_2               0   \n",
       "\n",
       "    true_negatives  false_negatives  false_positives  fdr  min_p_value  \\\n",
       "0          2936450           299030                0  NaN     0.189099   \n",
       "1          2936450           299030                0  NaN     0.189099   \n",
       "2          2936450           299030                0  NaN     0.189099   \n",
       "3          2936450           299030                0  NaN     0.189099   \n",
       "4          2936450           299030                0  NaN     0.189099   \n",
       "..             ...              ...              ...  ...          ...   \n",
       "85         3235178              302                0  NaN     0.432711   \n",
       "86         3235178              302                0  NaN     0.432711   \n",
       "87         3235178              302                0  NaN     0.432711   \n",
       "88         3235178              302                0  NaN     0.432711   \n",
       "89         3235178              302                0  NaN     0.432711   \n",
       "\n",
       "                      th  \n",
       "0                   0.05  \n",
       "1                 0.0005  \n",
       "2                  5e-06  \n",
       "3                  5e-08  \n",
       "4   0.016666666666666666  \n",
       "..                   ...  \n",
       "85                  0.05  \n",
       "86                0.0005  \n",
       "87                 5e-06  \n",
       "88                 5e-08  \n",
       "89  0.016666666666666666  \n",
       "\n",
       "[90 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2896c6c-a67b-4203-afbb-09c738539a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results_lmm_nopc_10env.csv').drop('Unnamed: 0',axis=1)\n",
    "\n",
    "df.columns\n",
    "\n",
    "# Calculate True Positive Rate (TPR) and False Positive Rate (FPR)\n",
    "df['tpr'] = df['true_positives'] / (df['true_positives'] + df['false_negatives'])\n",
    "df['fpr'] = df['false_positives'] / (df['false_positives'] + df['true_negatives'])\n",
    "\n",
    "df.sort_values('fdr')\n",
    "\n",
    "\n",
    "\n",
    "df = df[df['name'] == 'strongsel_mediumh_arq_highfreq_onehpoly_4']\n",
    "\n",
    "df['tpr'].diff()\n",
    "\n",
    "sum(df['tpr'].diff() * (df['fpr'].shift(-1) + df['fpr']) / 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Sort the DataFrame by 'significance_level'\n",
    "df = df.sort_values(by='th', ascending=False)\n",
    "\n",
    "# Calculate AUC (Area Under the Curve)\n",
    "auc = sum(df['tpr'].diff() * (df['fpr'].shift(-1) + df['fpr']) / 2)\n",
    "\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(df['fpr'], df['tpr'], marker='o', linestyle='-', color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='navy')\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(['ROC Curve (AUC = {:.2f})'.format(auc)])\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f'AUC: {auc:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cd05c6-f25f-4d63-8d1e-abbbb641fae5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859ddd50-aa41-4f27-a7e1-4d2e09254d66",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "406fa399-a613-4c85-af82-9fde8509e926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_rows(results_lmm):\n",
    "    max_value = results_lmm.index.str.split('.').str[1].astype(int).max()\n",
    "    expected_rows = [f'result.{i}' for i in range(1,max_value + 1)]\n",
    "    missing_rows = set(expected_rows) - set(results_lmm.index)\n",
    "    #check \n",
    "    #set(results_lmm.index) -  set(expected_rows)\n",
    "\n",
    "    # Initialize an empty list to store dictionaries\n",
    "    list_of_dicts = []\n",
    "\n",
    "    # Create dictionaries for each index value and add them to the list\n",
    "    for index in missing_rows:\n",
    "        new_row = {'index': index, 'R2m': np.nan, 'R2c': np.nan, 'beta': np.nan, 'beta_p': np.nan, 'BIC': np.nan}\n",
    "        list_of_dicts.append(new_row)\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    missing_rows = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "    results_lmm = results_lmm.reset_index()\n",
    "    results_lmm = pd.concat([results_lmm,missing_rows])\n",
    "    results_lmm['index'] = results_lmm['index'].str.split('.').str[1].astype(int)\n",
    "\n",
    "    results_lmm = results_lmm.sort_values(by = 'index')\n",
    "\n",
    "    results_lmm = results_lmm.reset_index(drop=True).drop('index',axis=1)\n",
    "    #len(results_lmm)\n",
    "\n",
    "    return results_lmm\n",
    "\n",
    "def metrics_wtreshold(name, results_lmm, th, min_pvalue):\n",
    "\n",
    "    results_lmm['sig'] = results_lmm['p_value_env']<= th\n",
    "\n",
    "    true_positives = len(results_lmm[(results_lmm['is_within_range'] ==True) & (results_lmm['sig'] ==True)])\n",
    "\n",
    "    true_negatives = len(results_lmm[(results_lmm['is_within_range'] ==False) & (results_lmm['sig'] ==False)])\n",
    "\n",
    "    false_negatives = len(results_lmm[(results_lmm['is_within_range'] ==True) & (results_lmm['sig'] ==False)])\n",
    "\n",
    "    false_positives = len(results_lmm[(results_lmm['is_within_range'] ==False) & (results_lmm['sig'] ==True)])\n",
    "\n",
    "    if false_positives + true_positives == 0:\n",
    "        fdr = np.nan  # Set FDR to 0 if the denominator is zero\n",
    "    else:\n",
    "        fdr = false_positives / (false_positives + true_positives)\n",
    "\n",
    "    new_row = {'name': name,\n",
    "               'true_positives': true_positives,\n",
    "               'true_negatives': true_negatives,\n",
    "               'false_negatives': false_negatives,\n",
    "               'false_positives': false_positives,\n",
    "               'fdr': fdr,\n",
    "               'min_p_value': min_pvalue, \n",
    "               'th': str(th)}\n",
    "\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4aeea47-9366-4422-ad7c-fc070bf66c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strongsel_mediumh_arq_highfreq_onehpoly_4\n",
      "here\n",
      "strongsel_lowh_arq_highfreq_onehpoly_4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m allele_freq_norm_file \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/lmm/lmm_nopc_results10env.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/allele_freq_norm10env.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m causal_loci_file \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marq\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124marq\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m result\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124marq\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/loci_effectsize.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m results_lmm \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m bc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.05\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(results_lmm)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m## first i need to check that all results are there \u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:889\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1034\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1088\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:1163\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/core/dtypes/common.py:1335\u001b[0m, in \u001b[0;36mis_extension_array_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;66;03m# Note: if other EA dtypes are ever held in HybridBlock, exclude those\u001b[39;00m\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;66;03m#  here too.\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;66;03m# NB: need to check DatetimeTZDtype and not is_datetime64tz_dtype\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m     \u001b[38;5;66;03m#  to exclude ArrowTimestampUSDtype\u001b[39;00m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, ExtensionDtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m   1331\u001b[0m         dtype, (DatetimeTZDtype, PeriodDtype)\n\u001b[1;32m   1332\u001b[0m     )\n\u001b[0;32m-> 1335\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_extension_array_dtype\u001b[39m(arr_or_dtype) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m \u001b[38;5;124;03m    Check if an object is a pandas extension array type.\u001b[39;00m\n\u001b[1;32m   1338\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[38;5;124;03m    False\u001b[39;00m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1380\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(arr_or_dtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, arr_or_dtype)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_metrics = pd.DataFrame(columns=['name', 'true_positives', 'true_negatives', 'false_negatives', 'false_positives', 'fdr', 'min_p_value', 'th'])\n",
    "\n",
    "for result in lmm_pc_results_files: \n",
    "    \n",
    "    name = result.split('/')[-3] + '_' + result.split('/')[-4] + '_' + result.split('/')[-5]\n",
    "    print(name)\n",
    "    allele_freq_norm_file = result.replace('/lmm/lmm_nopc_results10env.csv','/allele_freq_norm10env.csv')\n",
    "    causal_loci_file = result.split('arq')[0] + 'arq' + result.split('arq')[1].split('/')[0] + '/loci_effectsize.csv'\n",
    "\n",
    "    results_lmm = pd.read_csv(result,index_col=[0])\n",
    "\n",
    "    bc = 0.05 / len(results_lmm)\n",
    "\n",
    "    ## first i need to check that all results are there \n",
    "    results_lmm = add_missing_rows(results_lmm)\n",
    "    print('here')\n",
    "    ## read allele freq norm to get chrom pos \n",
    "    allele_freq_norm = pd.read_csv(allele_freq_norm_file)\n",
    "    results_lmm = pd.concat([allele_freq_norm['chrom_pos'], results_lmm],axis=1)\n",
    "\n",
    "    #get the causal loci \n",
    "    causal_loci = pd.read_csv(causal_loci_file)\n",
    "    causal_loci = causal_loci.merge(dict_offset_nooffset_partitions, left_on = 'pos', right_on = 'offset')\n",
    "    results_lmm = results_lmm.merge(dict_offset_nooffset_partitions[['offset', 'partition']], left_on = 'chrom_pos', right_on = 'offset')\n",
    "    results_lmm.loc[:, 'is_within_range'] = results_lmm['partition'].isin(causal_loci['partition'])\n",
    "\n",
    "\n",
    "    ## get the min p value for teh records \n",
    "    min_pvalue = results_lmm['p_value_env'].min()\n",
    "\n",
    "\n",
    "    for i in [0.05, 0.0005, 0.000005, 0.00000005, bc]:\n",
    "        new_row = metrics_wtreshold(name, results_lmm, i, min_pvalue)\n",
    "        result_metrics.loc[len(result_metrics)] = new_row\n",
    "result_metrics.to_csv('results_lmm_nopc_10env.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c349885-81fe-4b74-b42a-80b160987502",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>fdr</th>\n",
       "      <th>min_p_value</th>\n",
       "      <th>th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135084</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135084</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135084</td>\n",
       "      <td>5e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135084</td>\n",
       "      <td>5e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.135084</td>\n",
       "      <td>1.5453657571674064e-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        name  true_positives  true_negatives  \\\n",
       "0  strongsel_mediumh_arq_highfreq_onehpoly_4               0         2936450   \n",
       "1  strongsel_mediumh_arq_highfreq_onehpoly_4               0         2936450   \n",
       "2  strongsel_mediumh_arq_highfreq_onehpoly_4               0         2936450   \n",
       "3  strongsel_mediumh_arq_highfreq_onehpoly_4               0         2936450   \n",
       "4  strongsel_mediumh_arq_highfreq_onehpoly_4               0         2936450   \n",
       "\n",
       "   false_negatives  false_positives  fdr  min_p_value                      th  \n",
       "0           299030                0  NaN     0.135084                    0.05  \n",
       "1           299030                0  NaN     0.135084                  0.0005  \n",
       "2           299030                0  NaN     0.135084                   5e-06  \n",
       "3           299030                0  NaN     0.135084                   5e-08  \n",
       "4           299030                0  NaN     0.135084  1.5453657571674064e-08  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c1df198e-9087-49b6-a9fa-907e7c07c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "results1 = pd.read_csv(lmm_pc_results_files[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5cac74a9-2ae7-4a25-86d8-1ae15517b210",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2937025    0.135084\n",
       "2937097    0.135084\n",
       "1466144    0.135563\n",
       "296901     0.135806\n",
       "1007588    0.136768\n",
       "             ...   \n",
       "3017600    1.000000\n",
       "2817017    1.000000\n",
       "1079801    1.000000\n",
       "1079681    1.000000\n",
       "2237996    1.000000\n",
       "Name: p_value_env, Length: 3235480, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1['p_value_env'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616245f4-30a1-4d9f-b454-37c99e041b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snakemake_pipeline)",
   "language": "python",
   "name": "pipeline_snakemake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
