{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f1162e-bf4d-4153-8abb-c966e285ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## results model meixi \n",
    "## IMPORT ALLELES FREQ \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import rdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dafcca-1b23-47cd-a938-f698d20d9bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_offset_nooffset_partitions = pd.read_csv('/home/tbellagio/scratch/slim_grenenet/data/dict_offset_nooffset_partitions.csv')\n",
    "\n",
    "pattern = os.path.join('/home/tbellagio/scratch/slim_grenenet/results', '**', 'lmm_nopc_results10env.csv')\n",
    " \n",
    "lmm_pc_results_files = glob.glob(pattern, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bb1baf-6eaa-4ca4-9c77-5ea2b3386167",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_rows(results_lmm):\n",
    "    max_value = results_lmm.index.str.split('.').str[1].astype(int).max()\n",
    "    expected_rows = [f'result.{i}' for i in range(1,max_value + 1)]\n",
    "    missing_rows = set(expected_rows) - set(results_lmm.index)\n",
    "    #check \n",
    "    #set(results_lmm.index) -  set(expected_rows)\n",
    "\n",
    "    # Initialize an empty list to store dictionaries\n",
    "    list_of_dicts = []\n",
    "\n",
    "    # Create dictionaries for each index value and add them to the list\n",
    "    for index in missing_rows:\n",
    "        new_row = {'index': index, 'R2m': np.nan, 'R2c': np.nan, 'beta': np.nan, 'beta_p': np.nan, 'BIC': np.nan}\n",
    "        list_of_dicts.append(new_row)\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    missing_rows = pd.DataFrame(list_of_dicts)\n",
    "\n",
    "    results_lmm = results_lmm.reset_index()\n",
    "    results_lmm = pd.concat([results_lmm,missing_rows])\n",
    "    results_lmm['index'] = results_lmm['index'].str.split('.').str[1].astype(int)\n",
    "\n",
    "    results_lmm = results_lmm.sort_values(by = 'index')\n",
    "\n",
    "    results_lmm = results_lmm.reset_index(drop=True).drop('index',axis=1)\n",
    "    #len(results_lmm)\n",
    "\n",
    "    return results_lmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3897d5-208b-415a-b39f-7f9e2fa113be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_wtreshold(name, results_lmm, th, min_pvalue):\n",
    "\n",
    "    results_lmm['sig'] = results_lmm['p_value_env']<= th\n",
    "\n",
    "    true_positives = len(results_lmm[(results_lmm['is_within_range'] ==True) & (results_lmm['sig'] ==True)])\n",
    "\n",
    "    true_negatives = len(results_lmm[(results_lmm['is_within_range'] ==False) & (results_lmm['sig'] ==False)])\n",
    "\n",
    "    false_negatives = len(results_lmm[(results_lmm['is_within_range'] ==True) & (results_lmm['sig'] ==False)])\n",
    "\n",
    "    false_positives = len(results_lmm[(results_lmm['is_within_range'] ==False) & (results_lmm['sig'] ==True)])\n",
    "\n",
    "    if false_positives + true_positives == 0:\n",
    "        fdr = np.nan  # Set FDR to 0 if the denominator is zero\n",
    "    else:\n",
    "        fdr = false_positives / (false_positives + true_positives)\n",
    "\n",
    "    new_row = {'name': name,\n",
    "               'true_positives': true_positives,\n",
    "               'true_negatives': true_negatives,\n",
    "               'false_negatives': false_negatives,\n",
    "               'false_positives': false_positives,\n",
    "               'fdr': fdr,\n",
    "               'min_p_value': min_pvalue, \n",
    "               'th': str(th)}\n",
    "\n",
    "    return new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0ab855-b935-44ad-8e9b-2ba7df764496",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m results_lmm \u001b[38;5;241m=\u001b[39m add_missing_rows(results_lmm)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m## read allele freq norm to get chrom pos \u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m allele_freq_norm \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mallele_freq_norm_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m results_lmm \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([allele_freq_norm[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchrom_pos\u001b[39m\u001b[38;5;124m'\u001b[39m], results_lmm],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#get the causal loci \u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/io/parsers/readers.py:583\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1704\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1697\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1700\u001b[0m     (\n\u001b[1;32m   1701\u001b[0m         index,\n\u001b[1;32m   1702\u001b[0m         columns,\n\u001b[1;32m   1703\u001b[0m         col_dict,\n\u001b[0;32m-> 1704\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1705\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1707\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1708\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[0;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[1;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:812\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:873\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:848\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:859\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/mambaforge/envs/pipeline_snakemake/lib/python3.9/site-packages/pandas/_libs/parsers.pyx:2025\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'."
     ]
    }
   ],
   "source": [
    "result_metrics = pd.DataFrame(columns=['name', 'true_positives', 'true_negatives', 'false_negatives', 'false_positives', 'fdr', 'min_p_value', 'th'])\n",
    "\n",
    "for result in lmm_pc_results_files: \n",
    "\n",
    "    name = result.split('/')[-3] + '_' + result.split('/')[-4] + '_' + result.split('/')[-5]\n",
    "\n",
    "    allele_freq_norm_file = result.replace('/lmm/lmm_nopc_results10env.csv','/allele_freq_norm10env.csv')\n",
    "    causal_loci_file = result.split('arq')[0] + 'arq' + result.split('arq')[1].split('/')[0] + '/loci_effectsize.csv'\n",
    "\n",
    "    results_lmm = pd.read_csv(result,index_col=[0])\n",
    "\n",
    "    bc = 0.05 / len(results_lmm)\n",
    "\n",
    "    ## first i need to check that all results are there \n",
    "    results_lmm = add_missing_rows(results_lmm)\n",
    "\n",
    "    ## read allele freq norm to get chrom pos \n",
    "    allele_freq_norm = pd.read_csv(allele_freq_norm_file)\n",
    "    results_lmm = pd.concat([allele_freq_norm['chrom_pos'], results_lmm],axis=1)\n",
    "\n",
    "    #get the causal loci \n",
    "    causal_loci = pd.read_csv(causal_loci_file)\n",
    "    causal_loci = causal_loci.merge(dict_offset_nooffset_partitions, left_on = 'pos', right_on = 'offset')\n",
    "    results_lmm = results_lmm.merge(dict_offset_nooffset_partitions[['offset', 'partition']], left_on = 'chrom_pos', right_on = 'offset')\n",
    "    results_lmm.loc[:, 'is_within_range'] = results_lmm['partition'].isin(causal_loci['partition'])\n",
    "\n",
    "\n",
    "    ## get the min p value for teh records \n",
    "    min_pvalue = results_lmm['p_value_env'].min()\n",
    "\n",
    "\n",
    "    for i in [0.05, 0.0005, 0.000005, 0.00000005, bc]:\n",
    "        new_row = metrics_wtreshold(name, results_lmm, i, min_pvalue)\n",
    "        result_metrics.loc[len(result_metrics)] = new_row\n",
    "result_metrics.to_csv('results_lmm_nopc_10env.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61b2cf4f-ea8c-436e-b237-a73c6e4fe03f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>false_negatives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>fdr</th>\n",
       "      <th>min_p_value</th>\n",
       "      <th>th</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>5e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>5e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>strongsel_mediumh_arq_highfreq_onehpoly_4</td>\n",
       "      <td>0</td>\n",
       "      <td>2936450</td>\n",
       "      <td>299030</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.189099</td>\n",
       "      <td>0.016666666666666666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>strongsel_mediumh_arq_mediumfreq_monogen_2</td>\n",
       "      <td>0</td>\n",
       "      <td>3235178</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>strongsel_mediumh_arq_mediumfreq_monogen_2</td>\n",
       "      <td>0</td>\n",
       "      <td>3235178</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>strongsel_mediumh_arq_mediumfreq_monogen_2</td>\n",
       "      <td>0</td>\n",
       "      <td>3235178</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>5e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>strongsel_mediumh_arq_mediumfreq_monogen_2</td>\n",
       "      <td>0</td>\n",
       "      <td>3235178</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>5e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>strongsel_mediumh_arq_mediumfreq_monogen_2</td>\n",
       "      <td>0</td>\n",
       "      <td>3235178</td>\n",
       "      <td>302</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>0.016666666666666666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name  true_positives  \\\n",
       "0    strongsel_mediumh_arq_highfreq_onehpoly_4               0   \n",
       "1    strongsel_mediumh_arq_highfreq_onehpoly_4               0   \n",
       "2    strongsel_mediumh_arq_highfreq_onehpoly_4               0   \n",
       "3    strongsel_mediumh_arq_highfreq_onehpoly_4               0   \n",
       "4    strongsel_mediumh_arq_highfreq_onehpoly_4               0   \n",
       "..                                         ...             ...   \n",
       "85  strongsel_mediumh_arq_mediumfreq_monogen_2               0   \n",
       "86  strongsel_mediumh_arq_mediumfreq_monogen_2               0   \n",
       "87  strongsel_mediumh_arq_mediumfreq_monogen_2               0   \n",
       "88  strongsel_mediumh_arq_mediumfreq_monogen_2               0   \n",
       "89  strongsel_mediumh_arq_mediumfreq_monogen_2               0   \n",
       "\n",
       "    true_negatives  false_negatives  false_positives  fdr  min_p_value  \\\n",
       "0          2936450           299030                0  NaN     0.189099   \n",
       "1          2936450           299030                0  NaN     0.189099   \n",
       "2          2936450           299030                0  NaN     0.189099   \n",
       "3          2936450           299030                0  NaN     0.189099   \n",
       "4          2936450           299030                0  NaN     0.189099   \n",
       "..             ...              ...              ...  ...          ...   \n",
       "85         3235178              302                0  NaN     0.432711   \n",
       "86         3235178              302                0  NaN     0.432711   \n",
       "87         3235178              302                0  NaN     0.432711   \n",
       "88         3235178              302                0  NaN     0.432711   \n",
       "89         3235178              302                0  NaN     0.432711   \n",
       "\n",
       "                      th  \n",
       "0                   0.05  \n",
       "1                 0.0005  \n",
       "2                  5e-06  \n",
       "3                  5e-08  \n",
       "4   0.016666666666666666  \n",
       "..                   ...  \n",
       "85                  0.05  \n",
       "86                0.0005  \n",
       "87                 5e-06  \n",
       "88                 5e-08  \n",
       "89  0.016666666666666666  \n",
       "\n",
       "[90 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd06b009-762d-4063-a9c9-82b60a5bc55e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (snakemake_pipeline)",
   "language": "python",
   "name": "pipeline_snakemake"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
